{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 03: Concept 03\n",
    "\n",
    "## Regularization\n",
    "\n",
    "Import the relevant libraries and initialize the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "reg_lambda = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a helper method to split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(x_dataset, y_dataset, ratio):\n",
    "    arr = np.arange(x_dataset.size)\n",
    "    np.random.shuffle(arr)\n",
    "    num_train = int(ratio * x_dataset.size)\n",
    "    x_train = x_dataset[arr[0:num_train]]\n",
    "    y_train = y_dataset[arr[0:num_train]]\n",
    "    x_test = x_dataset[arr[num_train:x_dataset.size]]\n",
    "    y_test = y_dataset[arr[num_train:x_dataset.size]]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fake dataset. y = x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dataset = np.linspace(-1, 1, 100)\n",
    "\n",
    "num_coeffs = 9\n",
    "y_dataset_params = [0.] * num_coeffs\n",
    "y_dataset_params[2] = 1\n",
    "y_dataset = 0\n",
    "for i in range(num_coeffs):\n",
    "    y_dataset += y_dataset_params[i] * np.power(x_dataset, i)\n",
    "y_dataset += np.random.randn(*x_dataset.shape) * 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into 70% training and testing 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, x_test, y_train, y_test) = split_dataset(x_dataset, y_dataset, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the input/output placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, w):\n",
    "    terms = []\n",
    "    for i in range(num_coeffs):\n",
    "        term = tf.mul(w[i], tf.pow(X, i))\n",
    "        terms.append(term)\n",
    "    return tf.add_n(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the regularized cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable([0.] * num_coeffs, name=\"parameters\")\n",
    "y_model = model(X, w)\n",
    "cost = tf.div(tf.add(tf.reduce_sum(tf.square(Y-y_model)),\n",
    "                     tf.mul(reg_lambda, tf.reduce_sum(tf.square(w)))),\n",
    "              2*x_train.size)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out various regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('reg_lambda', 0.0)\n",
      "('final cost', 0.032030996)\n",
      "('reg_lambda', 0.010101010101010102)\n",
      "('final cost', 0.028902493)\n",
      "('reg_lambda', 0.020202020202020204)\n",
      "('final cost', 0.027128801)\n",
      "('reg_lambda', 0.030303030303030304)\n",
      "('final cost', 0.025800284)\n",
      "('reg_lambda', 0.040404040404040407)\n",
      "('final cost', 0.024812995)\n",
      "('reg_lambda', 0.050505050505050511)\n",
      "('final cost', 0.02407708)\n",
      "('reg_lambda', 0.060606060606060608)\n",
      "('final cost', 0.023520416)\n",
      "('reg_lambda', 0.070707070707070718)\n",
      "('final cost', 0.023091594)\n",
      "('reg_lambda', 0.080808080808080815)\n",
      "('final cost', 0.022754973)\n",
      "('reg_lambda', 0.090909090909090912)\n",
      "('final cost', 0.02248578)\n",
      "('reg_lambda', 0.10101010101010102)\n",
      "('final cost', 0.022266606)\n",
      "('reg_lambda', 0.11111111111111112)\n",
      "('final cost', 0.022085056)\n",
      "('reg_lambda', 0.12121212121212122)\n",
      "('final cost', 0.021932183)\n",
      "('reg_lambda', 0.13131313131313133)\n",
      "('final cost', 0.021801468)\n",
      "('reg_lambda', 0.14141414141414144)\n",
      "('final cost', 0.021688089)\n",
      "('reg_lambda', 0.15151515151515152)\n",
      "('final cost', 0.021588456)\n",
      "('reg_lambda', 0.16161616161616163)\n",
      "('final cost', 0.021499878)\n",
      "('reg_lambda', 0.17171717171717174)\n",
      "('final cost', 0.021420266)\n",
      "('reg_lambda', 0.18181818181818182)\n",
      "('final cost', 0.0213481)\n",
      "('reg_lambda', 0.19191919191919193)\n",
      "('final cost', 0.021282142)\n",
      "('reg_lambda', 0.20202020202020204)\n",
      "('final cost', 0.021221504)\n",
      "('reg_lambda', 0.21212121212121213)\n",
      "('final cost', 0.021165388)\n",
      "('reg_lambda', 0.22222222222222224)\n",
      "('final cost', 0.021113267)\n",
      "('reg_lambda', 0.23232323232323235)\n",
      "('final cost', 0.021064682)\n",
      "('reg_lambda', 0.24242424242424243)\n",
      "('final cost', 0.021019241)\n",
      "('reg_lambda', 0.25252525252525254)\n",
      "('final cost', 0.020976666)\n",
      "('reg_lambda', 0.26262626262626265)\n",
      "('final cost', 0.020936726)\n",
      "('reg_lambda', 0.27272727272727276)\n",
      "('final cost', 0.020899175)\n",
      "('reg_lambda', 0.28282828282828287)\n",
      "('final cost', 0.020863947)\n",
      "('reg_lambda', 0.29292929292929293)\n",
      "('final cost', 0.020830827)\n",
      "('reg_lambda', 0.30303030303030304)\n",
      "('final cost', 0.020799706)\n",
      "('reg_lambda', 0.31313131313131315)\n",
      "('final cost', 0.020770462)\n",
      "('reg_lambda', 0.32323232323232326)\n",
      "('final cost', 0.020743057)\n",
      "('reg_lambda', 0.33333333333333337)\n",
      "('final cost', 0.020717328)\n",
      "('reg_lambda', 0.34343434343434348)\n",
      "('final cost', 0.020693347)\n",
      "('reg_lambda', 0.35353535353535359)\n",
      "('final cost', 0.020670895)\n",
      "('reg_lambda', 0.36363636363636365)\n",
      "('final cost', 0.020649901)\n",
      "('reg_lambda', 0.37373737373737376)\n",
      "('final cost', 0.020630507)\n",
      "('reg_lambda', 0.38383838383838387)\n",
      "('final cost', 0.020612454)\n",
      "('reg_lambda', 0.39393939393939398)\n",
      "('final cost', 0.020595714)\n",
      "('reg_lambda', 0.40404040404040409)\n",
      "('final cost', 0.020580361)\n",
      "('reg_lambda', 0.4141414141414142)\n",
      "('final cost', 0.02056626)\n",
      "('reg_lambda', 0.42424242424242425)\n",
      "('final cost', 0.020553354)\n",
      "('reg_lambda', 0.43434343434343436)\n",
      "('final cost', 0.020541586)\n",
      "('reg_lambda', 0.44444444444444448)\n",
      "('final cost', 0.02053109)\n",
      "('reg_lambda', 0.45454545454545459)\n",
      "('final cost', 0.020521631)\n",
      "('reg_lambda', 0.4646464646464647)\n",
      "('final cost', 0.020513181)\n",
      "('reg_lambda', 0.47474747474747481)\n",
      "('final cost', 0.020505728)\n",
      "('reg_lambda', 0.48484848484848486)\n",
      "('final cost', 0.020499419)\n",
      "('reg_lambda', 0.49494949494949497)\n",
      "('final cost', 0.020493994)\n",
      "('reg_lambda', 0.50505050505050508)\n",
      "('final cost', 0.020489426)\n",
      "('reg_lambda', 0.51515151515151525)\n",
      "('final cost', 0.020485764)\n",
      "('reg_lambda', 0.5252525252525253)\n",
      "('final cost', 0.02048303)\n",
      "('reg_lambda', 0.53535353535353536)\n",
      "('final cost', 0.020481102)\n",
      "('reg_lambda', 0.54545454545454553)\n",
      "('final cost', 0.020479959)\n",
      "('reg_lambda', 0.55555555555555558)\n",
      "('final cost', 0.020479543)\n",
      "('reg_lambda', 0.56565656565656575)\n",
      "('final cost', 0.020479877)\n",
      "('reg_lambda', 0.5757575757575758)\n",
      "('final cost', 0.020481015)\n",
      "('reg_lambda', 0.58585858585858586)\n",
      "('final cost', 0.020482803)\n",
      "('reg_lambda', 0.59595959595959602)\n",
      "('final cost', 0.020485209)\n",
      "('reg_lambda', 0.60606060606060608)\n",
      "('final cost', 0.020488247)\n",
      "('reg_lambda', 0.61616161616161624)\n",
      "('final cost', 0.020491926)\n",
      "('reg_lambda', 0.6262626262626263)\n",
      "('final cost', 0.020496259)\n",
      "('reg_lambda', 0.63636363636363646)\n",
      "('final cost', 0.020501109)\n",
      "('reg_lambda', 0.64646464646464652)\n",
      "('final cost', 0.020506497)\n",
      "('reg_lambda', 0.65656565656565657)\n",
      "('final cost', 0.020512359)\n",
      "('reg_lambda', 0.66666666666666674)\n",
      "('final cost', 0.020518789)\n",
      "('reg_lambda', 0.6767676767676768)\n",
      "('final cost', 0.020525761)\n",
      "('reg_lambda', 0.68686868686868696)\n",
      "('final cost', 0.02053312)\n",
      "('reg_lambda', 0.69696969696969702)\n",
      "('final cost', 0.020540955)\n",
      "('reg_lambda', 0.70707070707070718)\n",
      "('final cost', 0.02054918)\n",
      "('reg_lambda', 0.71717171717171724)\n",
      "('final cost', 0.020557789)\n",
      "('reg_lambda', 0.72727272727272729)\n",
      "('final cost', 0.020566842)\n",
      "('reg_lambda', 0.73737373737373746)\n",
      "('final cost', 0.020576352)\n",
      "('reg_lambda', 0.74747474747474751)\n",
      "('final cost', 0.020586118)\n",
      "('reg_lambda', 0.75757575757575768)\n",
      "('final cost', 0.020596288)\n",
      "('reg_lambda', 0.76767676767676774)\n",
      "('final cost', 0.020606732)\n",
      "('reg_lambda', 0.77777777777777779)\n",
      "('final cost', 0.020617416)\n",
      "('reg_lambda', 0.78787878787878796)\n",
      "('final cost', 0.020628581)\n",
      "('reg_lambda', 0.79797979797979801)\n",
      "('final cost', 0.020639906)\n",
      "('reg_lambda', 0.80808080808080818)\n",
      "('final cost', 0.020651612)\n",
      "('reg_lambda', 0.81818181818181823)\n",
      "('final cost', 0.020663502)\n",
      "('reg_lambda', 0.8282828282828284)\n",
      "('final cost', 0.020675601)\n",
      "('reg_lambda', 0.83838383838383845)\n",
      "('final cost', 0.020687955)\n",
      "('reg_lambda', 0.84848484848484851)\n",
      "('final cost', 0.020700499)\n",
      "('reg_lambda', 0.85858585858585867)\n",
      "('final cost', 0.020713398)\n",
      "('reg_lambda', 0.86868686868686873)\n",
      "('final cost', 0.020726357)\n",
      "('reg_lambda', 0.8787878787878789)\n",
      "('final cost', 0.020739622)\n",
      "('reg_lambda', 0.88888888888888895)\n",
      "('final cost', 0.020752901)\n",
      "('reg_lambda', 0.89898989898989912)\n",
      "('final cost', 0.020766499)\n",
      "('reg_lambda', 0.90909090909090917)\n",
      "('final cost', 0.020780109)\n",
      "('reg_lambda', 0.91919191919191923)\n",
      "('final cost', 0.020793982)\n",
      "('reg_lambda', 0.92929292929292939)\n",
      "('final cost', 0.020807972)\n",
      "('reg_lambda', 0.93939393939393945)\n",
      "('final cost', 0.020822177)\n",
      "('reg_lambda', 0.94949494949494961)\n",
      "('final cost', 0.020836372)\n",
      "('reg_lambda', 0.95959595959595967)\n",
      "('final cost', 0.020850785)\n",
      "('reg_lambda', 0.96969696969696972)\n",
      "('final cost', 0.020865183)\n",
      "('reg_lambda', 0.97979797979797989)\n",
      "('final cost', 0.020879777)\n",
      "('reg_lambda', 0.98989898989898994)\n",
      "('final cost', 0.020894345)\n",
      "('reg_lambda', 1.0)\n",
      "('final cost', 0.020909095)\n"
     ]
    }
   ],
   "source": [
    "for reg_lambda in np.linspace(0, 1, 100):\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(train_op, feed_dict={X: x_train, Y: y_train})\n",
    "    final_cost = sess.run(cost, feed_dict={X: x_test, Y: y_test})\n",
    "    print('reg_lambda', reg_lambda)\n",
    "    print('final cost', final_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
